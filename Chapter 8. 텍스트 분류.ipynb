{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텍스트 분류(text classification) : 텍스트, 문장 또는 (문장들로 이루어진) 문서를 입력으로 받아 사전에 정의된 클래스 중에 어디에 속하는지 분류하는 과정\n",
    "\n",
    "* 텍스트 분류의 응용 분야\n",
    "\n",
    "\n",
    "| 문제 | 클래스 예시 | \n",
    "|:--------|:--------|\n",
    "| 감정 분석 | 긍정, 중립, 부정 |\n",
    "| 스팸 메일 탐지 | 정상, 스팸 | \n",
    "| 사용자 의도 분류 | 명령, 질문, 잡담 등 | \n",
    "| 주제 분류 | 각 주제 | \n",
    "| 카테고리 분류 | 각 카테고리 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 이전에 분류 방식\n",
    "    * 나이브 베이즈 분류(Naive Bayes) : 가장 간단한 분류 방식\n",
    "    * SVM(Support-Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 나이브 베이즈 활용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 나이브 베이즈\n",
    "    * 간단하지만 매우 강력한 분류 방식, 기대 이상의 성능을 가진다.\n",
    "    * 단어를 불연속적인 심볼(symbol)로 다룬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 MAP\n",
    "* 베이즈 정리(Bayes Theorem)\n",
    "* 데이터 D가 주어졌을 때 각 클래스 c의 확률  \n",
    "\n",
    "    $P(c|D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 토마스 베이즈의 베이즈 정리를 활용한 조건부 확률  \n",
    "\n",
    "    $ \\underbrace{P(c|D)}_\\text{posterior}  \n",
    "    = {{\\overbrace{P(D|c)}^\\text{likelihood}\\ \\overbrace{P(c)}^\\text{prior}} \\over \\underbrace{P(D)}_\\text{evidence}} \\\\\n",
    "    \\phantom{\\underbrace{P(c|D)}_\\text{posterior}}= {{P(D|c)P(c)} \\over {\\sum_{i=1}^{|C|} P(D|c_i)P(c_i)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 베이즈 법칙의 각 부분별 명칭\n",
    "\n",
    "| 수식 | 영어 명칭 | 한글 명칭| \n",
    "|:--------|:--------|:-|\n",
    "| $$P(c|D)$$ | posterior | 사후 확률|\n",
    "| $$P(D|c)$$ | likelihood | 가능도(우도)|\n",
    "| $$P(c)$$ | posterior | 사전 확률|\n",
    "| $$P(D)$$ | posterior | 증거|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(D)$ 구하기\n",
    "\n",
    "    * $P(c|D)$는 클래스 c에 관한 함수\n",
    "$$P(c|D) \\propto P(D|c)P(c)$$\n",
    "\n",
    "* 주어진 데이터 $D$ 만족하며 (사후)확률을 최대로 하는 클래스 $c$ 구하기\n",
    "    * 사후 확률 최대화(MAP, Maximum a posterior)\n",
    "    $$\\hat{c}_{MAP} = \\underset{c \\in \\mathcal{C}} {argmax} P(C = c| D)$$\n",
    "    * 데이터 $D$가 주어졌을 때 가능한 클래스 집합 c 중에서 사후 확률을 최대로 하는 클래스 D를 선택한다.\n",
    "    \n",
    "* 데이터 $D$가 나타날 가능도를 최대로 하는 클래스 $c$를 선택\n",
    "    * 최대가능도 추정(MLE)\n",
    "    \n",
    "    $$\\hat{c}_{MLE} = \\underset{c \\in \\mathcal{C}}{argmax} P(D|C=c)$$\n",
    "    * 주어진 데이터 D와 클래스 레이블 C가 있을 때, 확률 분포를 근사하기 위한 함수 파라미터 $\\theta$를 훈련하는 방법으로 활용\n",
    "    \n",
    "    $$\\hat{\\theta} = \\underset{\\theta}{argmax}P(C|D,\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLE vs MAP\n",
    "\n",
    "* MAP는 경우에 따라 MLE에 비해 더 정확할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 신발 크기(데이터, x) = 235 & 범인의 성별(클래스, y) 예측\n",
    "    * 성별 클래스 집합  \n",
    "        $Y = \\{male, female\\} \\\\\n",
    "        $  \n",
    "        \n",
    "    * 신발 크기(데이터) 집합      \n",
    "        $X = \\{\\cdots, 225, 230, 235, 240,\\cdots\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 범죄 현장이 남자들로 구성된 군부대라고 가정(불균형한 사전확률)\n",
    "    \n",
    "    $$P(y=male|x=235) > P(y=female|x=235),\n",
    "    \\\\ \\text{if}\\ P(x=235|y=male)P(y=male) > P(x = 235|y=female)P(y=female)$$\n",
    "    \n",
    "    $\\therefore$ 신발 크기가 235라고 해도 사전확률 자체가 매우 불균형하므로 여성이 범인일 것이라 예측할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 나이브 베이즈\n",
    "* MAP 기반\n",
    "* 대부분 사후 확률을 바로 구하기 어렵기 때문에 가능도와 사전 확률의 곱을 통해 클래스 $y$를 예측한다.\n",
    "* 사후 확률\n",
    "    * $n$개의 단어 $w_1, w_2, \\cdots, w_n$이 주어질 때, 문장이 $c$ 클래스에 속할 확률값\n",
    "    \n",
    "      $$P(y=c|x=w_1,w_2,\\cdots,w_n)$$\n",
    "    * x가 다양한 특징(feature)로 이루어진 데이터인 경우\n",
    "        * 훈련 데이터에서 매우 희소하다.\n",
    "        * 사후 확률뿐 아니라 가능도 $P(x=w_1,w_2,\\cdots,w_n|y=c)$구하기 어렵다.\n",
    "        * 확률은 코퍼스의 출현 빈도를 통해 추정 가능한데, 특징이 복잡할수록 가능도 또는 사후 확률을 만족하는 경우는 코퍼스에 매우 드물다.\n",
    "        * 확률값을 0으로 추정하는 오류 발생\n",
    "        * 나이브 베이즈로 해결할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 나이브 베이즈\n",
    "    * **각 특징이 독립적**이라고 가정\n",
    "    * 각 특징의 결합 확률을 각 독립된 확률의 곱으로 근사 가능\n",
    "        \n",
    "    $P(y=c|x=w_1,w_2,\\cdots,w_n) \\propto P(x=w_1,w_2,\\cdots,w_n|y=c)P(y=c) \\\\\n",
    "        \\phantom{P(y=c|x=w_1,w_2,\\cdots,w_n)}\\approx P(w_1|c)P(w_2|c)\\cdots P(w_n|c)P(c) \\\\\n",
    "        \\phantom{P(y=c|x=w_1,w_2,\\cdots,w_n)}= \\prod_{i=1}^n P(w_i|c)P(c)$\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MAP 활용한 클래스  \n",
    "    = 사후 확률을 최대화하는 클래스  \n",
    "    = 각 특징들의 확률의 곱에 사전 확률을 곱한 값을 최대화한 클래스(나이브 베이즈 가정)  \n",
    "\n",
    "    $\\hat{c} = \\underset{c \\in \\mathcal{C}} {\\text{argmax}} P(y=c|x = w_1,w_2,\\cdots,w_n) \\\\\n",
    "    \\phantom{\\hat{c}} \\approx \\underset{c \\in \\mathcal{C}} {\\text{argmax}} \\prod_{i=1}^n P(w_i|c)p(c)$\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사전 확률 : 실제 데이터(코퍼스)에서 출현한 빈도를 통해 추정 가능  \n",
    "\n",
    "    $P(y=c) \\approx {{Count(c)} \\over {\\sum_{i=1}^{|C|} Count(c_i)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각 특징(feature)별 가능도 확률  \n",
    "\n",
    "    $P(w|c) \\approx {{Count(w,c)} \\over {\\sum_{j=1}^{|V|} Count(w_j,c)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 예제: 감성 분석\n",
    "* 가장 많이 활용되는 텍스트 분류 기법\n",
    "    * 사용자 댓글이나 리뷰 등을 긍정 또는 부정으로 분류하여 마케팅이나 서비스 향상에 활용하는 방법\n",
    "    * 클래스 집합 C, 문서 d로 구성된 집합 D\n",
    "    $$\\mathcal{C} = \\{pos,neg\\} \\\\\n",
    "    \\mathcal{D} = \\{d_1,d_2,\\cdots\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'I am happy to see this movie!' 문장의 긍정/부정 판단\n",
    "* 긍정 감성  \n",
    "\n",
    "    $P(\\color{blue}{pos}|I, am, happy, to, see, this, movie, !) \\\\\n",
    "    \\phantom{P(\\color{blue}{pos})}= {P(I, am, happy, to, see, this, movie, !|\\color{blue}{pos})P(\\color{blue}{pos})\\over P(I, am, happy, to, see, this, movie, !)} \\\\\n",
    "    \\phantom{P(pos)}\\approx {P(I|\\color{blue}{pos})P(am|\\color{blue}{pos})P(happy|\\color{blue}{pos})\\cdots P(!|\\color{blue}{pos})P(\\color{blue}{pos})\\over P(I, am, happy, to, see, this, movie, !)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 긍정 감성에서 각 가능도 확률  \n",
    "    \n",
    "    $P(happy|\\color{blue}{pos}) \\approx {{Count(happy,\\color{blue}{pos})} \\over {\\sum_{j=1}^{|V|} Count(w_j,\\color{blue}{pos})}} \\\\\n",
    "    P({\\color{blue}{pos}}) \\approx {Count({\\color{blue}{pos}}) \\over {|\\mathcal{D}|}}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 부정 감성  \n",
    "\n",
    "    $P({\\color{orange}{neg}}|I, am, happy, to, see, this, movie, !) \\\\\n",
    "    \\phantom{P(neg)}= {P(I, am, happy, to, see, this, movie, !|{\\color{orange}{neg}})P({\\color{orange}{neg}})\\over P(I, am, happy, to, see, this, movie, !)} \\\\\n",
    "    \\phantom{P(neg)}\\approx {P(I|{\\color{orange}{neg}})P(am|{\\color{orange}{neg}})P(happy|{\\color{orange}{neg}})\\cdots P(!|{\\color{orange}{neg}})P({\\color{orange}{neg}})\\over P(I, am, happy, to, see, this, movie, !)}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 부정 감성에서 각 가능도 확률  \n",
    "\n",
    "    $P(happy|{\\color{orange}{neg}}) \\approx {{Count(happy,\\color{orange}{neg})} \\over {\\sum_{j=1}^{|V|} Count(w_j,{\\color{orange}{neg}})}} \\\\\n",
    "    P({\\color{orange}{neg}}) \\approx {Count({\\color{orange}{neg}}) \\over {|\\mathcal{D}|}}$\n",
    "    \n",
    "    \n",
    "$\\therefore$ 코퍼스에서 각 단어의 클래스당 출현 빈도를 계산하는 것만으로도 간단히 감성 분석 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 add-one Smoothing\n",
    "* 훈련 데이터에서 $Count(happy,\\color{orange}{neg})=0$이면 $P(happy|\\color{orange}{neg})=0$이 된다.\n",
    "* 훈련 데이터(코퍼스)에 존재하지 않으므로 해당 **샘플의 실제 출현 확률을 0으로 추정하는 것은 매우 위험**하다.  \n",
    "\n",
    "    $$P(happy|\\color{orange}{neg}) \\approx {{Count(happy,\\color{orange}{neg})} \\over {\\sum_{j=1}^{|V|} Count(w_j,\\color{orange}{neg})}} = 0, \\\\\n",
    "    \\text{where $Count(happy,\\color{orange}{neg})=0$}$$\n",
    "  \n",
    "* 각 출현 횟수에 1을 더하여 해결 가능하다.  \n",
    "\n",
    "    $${\\tilde{P}(w|c)} = {{Count(w,c)+1} \\over \\left({\\sum_{j=1}^{|V|} Count(w_j,c)}\\right)+|V|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.5 장점과 한계\n",
    "* 장점\n",
    "    * 단순히 출현 빈도를 세는 것처럼 쉽고 간단하고 강력한 감성 분석 구현 가능\n",
    "* 한계\n",
    "    * 문장 'I am not happy to see this movie!'\n",
    "    * 'not'이 추가되고 문장의 뜻은 정반대가 된다.\n",
    "    \n",
    "    $$P({\\color{blue}{pos}}|I, am, not, happy, to, see, this, movie, !) \\\\\n",
    "    P({\\color{orange}{neg}}|I, am, not, happy, to, see, this, movie, !)$$\n",
    "    \n",
    "    * 'not'은 'happy'를 수식하므로 서로 독립이 아니다.\n",
    "    $$P(not, happy) \\ne P(not)P(happy)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문장은 단어들이 순서대로 나타나 의미를 이룬다.\n",
    "    * 각 단어의 출현 여부 중요\n",
    "    * **단어 간 순서로 인해 생기는 관계와 정보**도 중요하다.\n",
    "    * '각 특징은 서로 독립적이다.'(나이브 베이즈 가정)은 이를 반영하지 못하여 한계가 발생한다.\n",
    "    * 딥러닝 활용하기에 레이블당 문장 수가 매우 적은 경우에는 더 나을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 흔한 오해2\n",
    "> 표제어 추출(lemmatization) 또는 어간 추출(stemming) 수행하여 접사 등을 제거한 이후에 텍스트 분류를 적용해야 하나요?\n",
    "\n",
    "* '나는 학교에 가요.'(원문)\n",
    "\n",
    "* 어간 추출 결과 \n",
    "\n",
    "| 단계 | 문장 | \n",
    "|:--------|:--------|\n",
    "| 원문 | 나는 학교에 가요. |\n",
    "| 전처리 | 나 는 학교 에 가 요 . | \n",
    "| 추출 | 나 학교 가 . | \n",
    "\n",
    "* 원문과 비교하면 희소성 문제를 줄일 수 있다.\n",
    "    * 같은 어간 추출 결과가 나올 수 있는 입력 문장 사례가 다양하다.\n",
    "    * 작은 코퍼스에서 효과 발휘(같은 결과가 나타남)\n",
    "    * '나 학교 가 .'\n",
    "\n",
    "| 번호 | 문장 | \n",
    "|:--------|:--------|\n",
    "| 1 | 나는 학교에 가요. |\n",
    "| 2 | 나도 학교로 가요. | \n",
    "| 3 | 나는 학교를 가요. |\n",
    "| | $\\dots$ |\n",
    "\n",
    "* 코퍼스가 부족한 상황에서는 희소성 문제 해결에 도움을 준다.\n",
    "    * 어간이나 표제어가 같은 문장에 대해 같은 샘플로 취급\n",
    "    * 머신러닝 방법에서 단어 및 문장은 불연속적이므로 희소성 문제에 치명적인 단점이 있고 이를 보완함.\n",
    "    \n",
    "* 딥러닝은 성공적으로 차원 축소 수행 가능\n",
    "    * 희소성 관련 문제가 크지 않다.\n",
    "    * 반드시 표제어 추출 및 어간 추출할 필요가 없다.\n",
    "    * 어간 추출 과정에서 분류에 필요한 정보가 생략된다.\n",
    "        * 감정 분석에서 텍스트 분류가 어려워질 수 있다.\n",
    "    \n",
    "| 원문 | 추출 후 | 정답 | \n",
    "|:--------|:--------|:--------|\n",
    "| 나는 학교에 가요. | 나 학교 가. |긍정 또는 중립|\n",
    "| 나만 학교에 가요. | 나 학교 가. |부정|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\therefore$ 딥러닝에서 표제어 또는 어간 추출 하기 전에 신경망 모델을 사용하여 텍스트 분류 문제 해결 시도 및 베이스 라인 성능을 확보한다.\n",
    "* 이후 성능 향상 차원에서 튜닝 및 시도할 때 코퍼스 양의 부족이 문제가 될 때 표제어 추출이나 어간 추출을 추가로 실험하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 RNN 활용하기\n",
    "* 문장은 단어들의 시퀀스로 이루어진 시퀀셜 데이터\n",
    "* 각 위치 또는 time-step의 단어들은 다른 위치의 단어들과 서로 영향을 주고받는다.\n",
    "* 이를 반영하는 것은 RNN이 적절하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* REVIEW  \n",
    "    * RNN은 각 time-step의 단어를 입력으로 받아 자신의 은닉 상태를 업데이트한다. \n",
    "    \n",
    "    $$h_t = f_{\\theta}(x_t,h_{t-1}) \\\\ $$\n",
    "    * n개의 단어로 이루어진 문장 x, 이를 RNN에 피드포워드하면 n개의 은닉 상태를 얻는다.\n",
    "    * 가장 마지막 은닉 상태를 활용하여 텍스트의 클래스를 분류할 수 있다.\n",
    "    \n",
    "    $$\\hat{y} = \\underset{y \\in \\mathcal{Y}} {argmax} P(y|x;\\theta) \\\\\n",
    "\\text{where $P(y|x;\\theta) = h_n = f_{\\theta}(x_n, h_{n-1})$ and $x = \\{w_1,w_2,\\cdots,w_n\\}$}\\\\ $$\n",
    "\n",
    "    $\\therefore$ RNN은 입력으로 주어진 문장을 분류 문제에 맞게 인코딩한다.  \n",
    "    = RNN의 출력값은 문장 임베딩 벡터라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1 아키텍처 내부 살펴보기\n",
    "<img src=\"./asset/8-4-1.png\" width=\"600\" height=\"600\">  \n",
    "\n",
    "\n",
    "* RNN을 통해 텍스트 분류 구현하는 구조\n",
    "\n",
    "* 텍스트에서 단어는 불연속값\n",
    "    * 문장이 되어도 그 값은 불연속이다.  \n",
    "    = 이산 확률 분포에서 문장을 샘플링한다.\n",
    "    * 입력으로 원핫 벡터들이 여러 time-step으로 주어진다.\n",
    "    * 입력은 3차원의 텐서이고 크기는 $n \\times m \\times |V|$이 될 것이다. ($n$ 배치크기, $m$ 문장 길이)\n",
    "    \n",
    "    $$x \\sim P(x) \n",
    "\\\\ \\text{where $x = \\{w_1,w_2,\\cdots,w_m\\}$ and $w_i \\in \\{0,1\\}^{|V|}$ and $|w_i|=1$} \n",
    "\\\\ \\therefore |x_{1:n}| = (n,m,|V|)\n",
    "\\\\ \\text{where $x_{1:n} = [x_1,x_2,\\cdots,x_n]$ and $n$ = batch_size} \\\\\n",
    "    $$\n",
    "    \n",
    "    * 원핫 벡터별로 1의 위치 인덱스만 기억하면 된다.(6장 참고)\n",
    "    * 원핫 벡터는 위치 인덱스 값인 0부터 $|V|-1$ 사이의 정수 표현 가능  \n",
    "    = 2차원의 행렬 $n \\times m$ 으로 충분  \n",
    "    $$ |x_{1:n}| = (n,m,1) = (n,m)\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 원핫 인코딩된 $n \\times m$텐서를 임베딩 계층에 통과시키면 단어 임베딩 텐서를 얻는다.\n",
    "* 단어 임베딩 텐서의 크기\n",
    "$$\\tilde{x}_{1:n} = emb_{\\theta}(x_{1:n}) \n",
    "\\\\ |\\tilde{x}_{1:n}|\\ \\text{where $d$ = word_vec_dim}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단어 임베딩 텐서를 RNN에 통과시킨다.\n",
    "$$h_t = RNN_{\\theta}(x_t,h_{t-1}) \n",
    "\\\\ \\text{where $|x_t|=(n,1,d),|h_t|=(n,1,h)$ and $h=$ hidden_size}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 초기 은닉 상태 $h_0$와 전체 입력(단어 임베딩 텐서 $x_{1:n}$) RNN에 입력\n",
    "* 파이토치의 최적화된 구현으로 빠르게 모든 time-step에 대한 출력과 마지막 은닉 상태 반환\n",
    "$$H = RNN_{\\theta}(x_{1:n},h_0)\n",
    "\\\\ \\text{where $H=[h_1;h_2;\\cdots;h_m]$ and $|H| = (n,m,h)$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 파이토치 RNN의 출력값 중 제일 마지막 time-step만 선택\n",
    "    * softmax 레이어 통과시켜 이산 확률 분포$P(y|x;\\theta)$ 로 나타낸다.\n",
    "* time-step의 차원에서 맨 마지막 인덱스를 슬라이싱(slicing) 후, 이를 리니어 계층을 거친 후에 softmax 함수를 취한다.\n",
    "$$h_m=H[:, -1]\n",
    "\\\\ \\hat{y} = \\text{softmax}(h_m \\cdot W + b)\n",
    "\\\\ \\text{where $|\\hat{y}=(n,|\\mathcal{C}|), |h_m|=(n,1,h), W \\in \\mathbb{R}^{h\\times|\\mathcal{C}|}$ and $b \\in \\mathbb{R}^{|\\mathcal{C}|}$} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\hat{y}$는 데이터 $x$와 확률 분포 함수 파라미터 $\\theta$가 주어질 때, 클래스를 나타내는 확률 변수 $y$의 분포를 나타낸다.\n",
    "* 실제 정답 $y$와 $\\hat{y}$ 차이의 손실 값을 구하고 최소화하도록 경사하강법을 통한 최적화 수행하여 신경망 $\\theta$를 훈련한다.\n",
    "$$\\mathcal{L}(\\hat{y},y) = - {1 \\over n} \\sum_{i=1}^n y_i \\log\\hat{y}_i$$\n",
    "* 교차 엔트로피 수식을 통해 실제 확률 분포에 신경망 확률 분포 함수가 근사하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $y_i$ 원핫 벡터이므로 **1인 인덱스의 로그 확률(log probability)값만 최대화**하면 된다.\n",
    "* 원핫 벡터로 구성된 정답 샘플과 신경망을 통해 얻은 이산 확률 분포 사이의 손실 함수 계산\n",
    "\n",
    "* 손실 함수에 대해 확률 분포 함수 신경망 파라미터 $\\theta$로 미분\n",
    "    * 가능도를 최대화하는 $\\theta$를 업데이트할 수 있다.\n",
    "    $$ \\theta \\leftarrow \\theta - \\lambda\\Delta_{\\theta} \\mathcal{L}(\\hat{y},y)\n",
    "    $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2 파이토치 예제 구현하기\n",
    "* 여러 계층으로 구성된 LSTM 사용\n",
    "* 내부의 각 레이어간에 드롭아웃 추가\n",
    "* 교차 엔트로피 손실 함수\n",
    "    * NLL 손실 함수로 최적화\n",
    "    * 일반적인 softmax 함수 대신 로그 확률을 반환하는 logsoftmax 함수 사용\n",
    "* 텍스트 분류기(text classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                input_size,\n",
    "                word_vec_dim,\n",
    "                hidden_size,\n",
    "                n_classes,\n",
    "                n_layers=4,\n",
    "                dropout_p=.3\n",
    "                ):\n",
    "        self.input_size = input_size # 단어 크기\n",
    "        self.word_vec_dim = word_vec_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_dim)\n",
    "        self.rnn = nn.LSTM(input_size=word_vec_dim,\n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=n_layers,\n",
    "                          dropout=dropout_p,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True\n",
    "                          )\n",
    "        self.generator = nn.Linear(hidden_size * 2, n_classes)\n",
    "        # 우리는 Logsoftmax + NLL 손실 함수를 사용한다. \n",
    "        # Softmax + CrossEntropy 손실 함수를 쓰지 않는다.\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # |x| = (bath_size, length)\n",
    "        x = self.emb(x)\n",
    "        # |x| = (batch_size, length, word_vec_dim)\n",
    "        x, _ = self.rnn(x)\n",
    "        # |x| = (batch_size, length, hidden_size * 2)\n",
    "        y = self.activation(self.generator(x[:, -1]))\n",
    "        # |y| = (batch_size, n_classes)\n",
    "        \n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
